{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Twitter Networks\n",
    "\n",
    "So far we collected Tweet IDs, dehydrated them to get actual content, identified users, and colledted Botometer scores for those users. \n",
    "\n",
    "Let's put all these information together in this final step and see what we can learn from the network and the available metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T04:24:13.597551Z",
     "start_time": "2020-06-18T04:24:12.201204Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "import gzip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from dateutil.parser import parse\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "from config import DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T04:24:13.629687Z",
     "start_time": "2020-06-18T04:24:13.600169Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'created_at': 'Sun May 10 20:28:06 +0000 2020', 'id': 1259580998586716162, 'id_str': '1259580998586716162', 'text': '#MilliHesaplarTakipte', 'truncated': False, 'entities': {'hashtags': [{'text': 'MilliHesaplarTakipte', 'indices': [0, 21]}], 'symbols': [], 'user_mentions': [], 'urls': []}, 'source': '<a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>', 'in_reply_to_status_id': None, 'in_reply_to_status_id_str': None, 'in_reply_to_user_id': None, 'in_reply_to_user_id_str': None, 'in_reply_to_screen_name': None, 'user': {'id': 913841350130520065, 'id_str': '913841350130520065', 'name': 'ðŸ‡¹ðŸ‡·ðŸ‡¹ðŸ‡·Engin DeÄŸirmenciðŸ‡¹ðŸ‡·ðŸ‡¹ðŸ‡·', 'screen_name': 'huduluengin75', 'location': '', 'description': 'ERZÄ°NCAN lÄ± heyecanlÄ±.', 'url': None, 'entities': {'description': {'urls': []}}, 'protected': False, 'followers_count': 157, 'friends_count': 257, 'listed_count': 0, 'created_at': 'Fri Sep 29 19:02:11 +0000 2017', 'favourites_count': 6401, 'utc_offset': None, 'time_zone': None, 'geo_enabled': False, 'verified': False, 'statuses_count': 1725, 'lang': None, 'contributors_enabled': False, 'is_translator': False, 'is_translation_enabled': False, 'profile_background_color': 'F5F8FA', 'profile_background_image_url': None, 'profile_background_image_url_https': None, 'profile_background_tile': False, 'profile_image_url': 'http://pbs.twimg.com/profile_images/1234735265585008642/wvRkfZeX_normal.jpg', 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1234735265585008642/wvRkfZeX_normal.jpg', 'profile_link_color': '1DA1F2', 'profile_sidebar_border_color': 'C0DEED', 'profile_sidebar_fill_color': 'DDEEF6', 'profile_text_color': '333333', 'profile_use_background_image': True, 'has_extended_profile': True, 'default_profile': True, 'default_profile_image': False, 'following': False, 'follow_request_sent': False, 'notifications': False, 'translator_type': 'none'}, 'geo': None, 'coordinates': None, 'place': None, 'contributors': None, 'is_quote_status': False, 'retweet_count': 0, 'favorite_count': 0, 'favorited': False, 'retweeted': False, 'lang': 'und'}\n"
     ]
    }
   ],
   "source": [
    "def iterate_tweet_content():\n",
    "    with gzip.open('../data/tweets_dehydrated.jsons.gz', 'rb') as fl:\n",
    "        for line in fl:\n",
    "            tweet = json.loads(line)\n",
    "            yield tweet\n",
    "            \n",
    "for tweet in iterate_tweet_content():\n",
    "    print(tweet)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T05:51:06.187144Z",
     "start_time": "2020-06-18T05:49:48.622200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 0\n",
      "Number of edges: 0\n",
      "\n",
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 203995\n",
      "Number of edges: 390375\n",
      "Average in degree:   1.9136\n",
      "Average out degree:   1.9136\n"
     ]
    }
   ],
   "source": [
    "# Build retweet - mention - reply network\n",
    "\n",
    "userProfile = dict()\n",
    "infoNet = nx.DiGraph() # Keep stats of min&max dates, count etc.\n",
    "for c,tweet in enumerate(iterate_tweet_content()):\n",
    "    connections = list()\n",
    "    tdate = parse(tweet['created_at'])\n",
    "    uid = tweet['id_str']\n",
    "    if uid not in userProfile:\n",
    "        userProfile[uid] = tweet['user']\n",
    "    \n",
    "    if tweet['in_reply_to_user_id'] != None:\n",
    "        connections.append((uid, tweet['in_reply_to_user_id'], 'reply'))\n",
    "        \n",
    "    if 'retweeted_status' in tweet:\n",
    "        rid = tweet['retweeted_status']['user']['id_str']\n",
    "        connections.append((rid, uid, 'retweet'))\n",
    "        if rid not in userProfile:\n",
    "            userProfile[rid] = tweet['retweeted_status']['user']\n",
    "    \n",
    "    for m in tweet['entities']['user_mentions']:\n",
    "        connections.append((uid, m['id_str'], 'mention'))\n",
    "    \n",
    "    for conn in connections:\n",
    "        if not infoNet.has_edge(conn[0], conn[1]):\n",
    "            infoNet.add_edge(conn[0], conn[1], reply=0, retweet=0, mention=0,\n",
    "                             datemin=tdate, datemax=tdate, count=0)\n",
    "        \n",
    "        infoNet[conn[0]][conn[1]][conn[2]] += 1\n",
    "        infoNet[conn[0]][conn[1]]['datemin'] = min(infoNet[conn[0]][conn[1]]['datemin'], tdate)\n",
    "        infoNet[conn[0]][conn[1]]['datemax'] = max(infoNet[conn[0]][conn[1]]['datemax'], tdate)\n",
    "        infoNet[conn[0]][conn[1]]['count'] += 1\n",
    "        \n",
    "        \n",
    "    if (c % 1000000) == 0:\n",
    "        print(nx.info(infoNet))\n",
    "    \n",
    "print(nx.info(infoNet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T05:51:07.640484Z",
     "start_time": "2020-06-18T05:51:06.189483Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for n in infoNet.nodes():\n",
    "    if n not in userProfile:\n",
    "        continue\n",
    "    infoNet.nodes[n]['nfriends'] = userProfile[n]['friends_count']\n",
    "    infoNet.nodes[n]['nfollowers'] = userProfile[n]['followers_count']\n",
    "    infoNet.nodes[n]['nstatuses'] = userProfile[n]['statuses_count']\n",
    "    infoNet.nodes[n]['nfavorites'] = userProfile[n]['favourites_count']\n",
    "    \n",
    "    infoNet.nodes[n]['screen_name'] = userProfile[n]['screen_name']\n",
    "    infoNet.nodes[n]['user_name'] = userProfile[n]['name']\n",
    "    infoNet.nodes[n]['creation_year'] = userProfile[n]['created_at'].split()[-1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T05:51:09.149915Z",
     "start_time": "2020-06-18T05:51:07.643577Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for 64066 accounts already collected\n",
      "1171 accounts unaccessible\n"
     ]
    }
   ],
   "source": [
    "# Read Botometer Scores\n",
    "\n",
    "BOTOMETER_SCORE_FILE = '../data/botometer_scores.jsons'\n",
    "BOTOMETER_ERROR_FILE = '../data/botometer_scores.errors'\n",
    "\n",
    "## Collect already existing scores from previous runs\n",
    "botometerScores = dict()\n",
    "try:\n",
    "    with open(BOTOMETER_SCORE_FILE, 'r') as fl:\n",
    "        for line in fl:\n",
    "            try:\n",
    "                temp = json.loads(line)\n",
    "                botometerScores[temp['user']['id_str']] = temp\n",
    "            except:\n",
    "                pass\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "print('Scores for {} accounts already collected'.format(len(botometerScores)))\n",
    "\n",
    "\n",
    "## Collect IDs of the accounts that are either deleted or suspended\n",
    "removedAccounts = set()\n",
    "try:\n",
    "    with open(BOTOMETER_ERROR_FILE, 'r') as fl:\n",
    "        for line in fl:\n",
    "            removedAccounts.add(line.strip())\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "print('{} accounts unaccessible'.format(len(removedAccounts)))\n",
    "\n",
    "\n",
    "### Add Botometer Scores to network\n",
    "\n",
    "for n in infoNet.nodes():\n",
    "    if n in botometerScores:\n",
    "        infoNet.nodes[n]['botometer_eng'] = np.ceil(botometerScores[n]['scores']['english']*5)\n",
    "        infoNet.nodes[n]['botometer_uni'] = np.ceil(botometerScores[n]['scores']['universal']*5)\n",
    "    \n",
    "    if n in removedAccounts:\n",
    "        infoNet.nodes[n]['botometer_eng'] = -1\n",
    "        infoNet.nodes[n]['botometer_uni'] = -1\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T05:51:26.681476Z",
     "start_time": "2020-06-18T05:51:20.802089Z"
    }
   },
   "outputs": [],
   "source": [
    "for u,v,d in infoNet.edges.data():\n",
    "    infoNet[u][v]['datemin'] = infoNet[u][v]['datemin'].strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    infoNet[u][v]['datemax'] = infoNet[u][v]['datemax'].strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "degreeSeq = {n:d for n,d in infoNet.degree()}\n",
    "for n in sorted(degreeSeq, key=degreeSeq.get, reverse=True)[:100]:\n",
    "    if n in userProfile:\n",
    "        infoNet.nodes[n]['viz_label'] = userProfile[n]['screen_name']\n",
    "    \n",
    "#nx.write_gexf(infoNet, '../data/demo_infonet-alldata.gexf')\n",
    "#nx.write_gexf(infoNet, '{}/demo_infonet-alldata.gexf'.format(DATA_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T05:51:32.987389Z",
     "start_time": "2020-06-18T05:51:26.684378Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 15710\n",
      "Number of edges: 45150\n",
      "Average in degree:   2.8740\n",
      "Average out degree:   2.8740\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\ntoRemove = set(infoNet.nodes()) - (removedAccounts | set(botometerScores.keys()))\\nprint(len(toRemove))\\n\\nfor n in toRemove:\\n    infoNet.remove_node(n)\\n\\nprint(nx.info(infoNet))\\nnx.write_gexf(infoNet, '../data/demo_infonet-subnet.gexf')\\n\""
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "toRemove = list()\n",
    "for n,d in infoNet.degree():\n",
    "    if d < 5:\n",
    "        toRemove.append(n)\n",
    "\n",
    "for n in toRemove:\n",
    "    infoNet.remove_node(n)\n",
    "    \n",
    "print(nx.info(infoNet))\n",
    "nx.write_gexf(infoNet, '../data/demo_infonet-filtered.gexf')\n",
    "\n",
    "'''\n",
    "toRemove = set(infoNet.nodes()) - (removedAccounts | set(botometerScores.keys()))\n",
    "print(len(toRemove))\n",
    "\n",
    "for n in toRemove:\n",
    "    infoNet.remove_node(n)\n",
    "\n",
    "print(nx.info(infoNet))\n",
    "nx.write_gexf(infoNet, '../data/demo_infonet-subnet.gexf')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T05:04:59.353179Z",
     "start_time": "2020-06-18T05:04:49.532889Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hashtag similarity network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze network data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
